{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    }
   ],
   "source": [
    "from zvsn_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading images from folder and preparing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting the images from the data folder\n",
      "2 classes were found:['Normal' 'Zoomed']\n",
      "Total number of images in the dataset: 2041\n",
      "Dimensions of images in the dataset: (150, 150, 3)\n"
     ]
    }
   ],
   "source": [
    "img_width, img_height = 150, 150\n",
    "X,y = prepare_data(\"../../dataset/Normal_vs_Zoomed\", 150, 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 150, 150, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the dataset into train, test and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 1632, Val set size: 205, Test set size: 204\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Splitting \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=33)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5, random_state=33)\n",
    "print(\"Train set size: {0}, Val set size: {1}, Test set size: {2}\".format(len(X_train), len(X_val), len(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a preview folder to view preprocessed images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!rm -r preview\n",
    "!mkdir preview\n",
    "\n",
    "i = 0\n",
    "for batch in datagen.flow(dataset[:1], batch_size=1,\n",
    "                          save_to_dir='preview', save_prefix='test', save_format='jpeg'):\n",
    "    i += 1\n",
    "    if i > 5:\n",
    "        break  # otherwise the generator would loop indefinitely\n",
    "\n",
    "!ls preview/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "from IPython.display import Image as _Imgdis\n",
    "from PIL import Image\n",
    "\n",
    "modified_images = glob.glob('preview/**/*jpeg')\n",
    "for img in modified_images:\n",
    "    display(_Imgdis(filename=img))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get model definition\n",
    "model = zvsn_model()\n",
    "\n",
    "# train model\n",
    "model.fit_generator(datagen.flow(X_train, y_train, batch_size=128),\n",
    "                    steps_per_epoch=len(X_train) / 128, validation_data=(X_val,y_val), epochs=10,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save model\n",
    "model.save('zoomed_vs_normal.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the model and applying it on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 148, 148, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 148, 148, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 74, 74, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 72, 72, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 72, 72, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 36, 36, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 34, 34, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 34, 34, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 17, 17, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 18496)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                1183808   \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 65        \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 1,212,513\n",
      "Trainable params: 1,212,513\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('zoomed_vs_normal.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get predictions for test set\n",
    "y_test_pred = predict(model, datagen, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.86      0.90        71\n",
      "          1       0.93      0.98      0.95       133\n",
      "\n",
      "avg / total       0.94      0.94      0.94       204\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get classification metrics \n",
    "print_metrics(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[ 116.96533966,  116.96533966,  116.96533966]]], dtype=float32),\n",
       " array([[[ 79.82288361,  79.79962921,  75.93218994]]], dtype=float32))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datagen.mean, datagen.std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict on other dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load model\n",
    "from keras.models import load_model\n",
    "model = load_model('zoomed_vs_normal.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def preprocess(X):\n",
    "    mean = np.array([27.04171, 27.04171, 27.04171]).reshape(1,1,3)\n",
    "    std = np.array([83.20263, 83.20263, 83.20263]).reshape(1,1,3)\n",
    "    X -= mean\n",
    "    X /= (std + K.epsilon())\n",
    "    return X    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# preprocess images\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "test_datagen = ImageDataGenerator(preprocessing_function=preprocess)\n",
    "sample_images = test_datagen.flow_from_directory(\"../../dataset/Normal_vs_Zoomed/Normal/\",\n",
    "                                              target_size=(150,150),\n",
    "                                              class_mode=None,\n",
    "                                              shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get predictions\n",
    "%%time\n",
    "predictions = model.predict_generator(sample_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# transform predictions into a dataframe\n",
    "import pandas as pd\n",
    "pred_df = pd.DataFrame({'filenames':cargo_test.filenames,'predictions':predictions.ravel()})\n",
    "pred_df['label'] = (pred_df.predictions > 0.5).astype(int)\n",
    "pd.options.display.max_colwidth=-1\n",
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# view images that are predicted as zoomed by the model\n",
    "for img in pred_df[pred_df.label==1].sample(frac=1.0).head().iterrows():\n",
    "    display(_Imgdis(filename='../datasets/Normal_vs_Zoomed/test/'+img[1].filenames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# view images that are predicted as normal by the model\n",
    "for img in pred_df[pred_df.label==0].sample(frac=1.0).head().iterrows():\n",
    "    display(_Imgdis(filename='../datasets/Normal_vs_Zoomed/test/'+img[1].filenames))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Atlas",
   "language": "python",
   "name": "atlas"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
